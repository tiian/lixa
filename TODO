Test query recovery step 24 crash: it needs a new crash point in client; what happens to the transaction? Will it passed a second time to a new client? See test case CT/0.0/6.1
	if the client crashes after a message QUERY RECOVERY (step=24), the
	server removes the status records, but recognize the crash and 
	insert in the recovery table a record pointing to an empty status
	transaction. The client re-connects, it is notified for recovery
	pending status, it retrieves a NULL transaction for server with a
	state does not need recovery. The global behavior is not bugged but
	it is useless the recovery round trip for a recovery MUST NOT performed
	Fix it!

Restart from ct_1_2.at ...
In server code, put crash point after message responses: they can exploit
bugs in the client code.
Crash test must be performed: put a crash point inside thread_status_sync_files

Remove all @@@ from source code: every one was/is an "open point"

Try this scenario:
- a multithread application
- one thread connects to a resource manager like Oracle or DB2 using tx_open()
- after tx_open() the server crashes, for example in server_xa_start_24
- the thread calls tx_commit() after some native SQL update operations
- the server crashed, the thread receive TX_FAIL from the transaction manager
- the thread can not close the connection to the database using tx_close()
  because after TX_FAIL the transaction manager can no longer perform work on
  behalf of the application
- what happens with locks inside the database(s)?
- is it right to document the application must close the resource managers by
  itself after a TX_FAIL return code??
- is it sufficient thread termination to clean-up database(s) state(s)?
- generally tx_close() can not be executed: some times it may happen, some 
  times it can not work properly

Document a memory leak introduced by libxml2:
xmlInitParser()
xmlCleanupParser()
must be called from the same thread (cite the thread/libxml2 URL).
If xmlCleanupParser() is called from a different thread, 1 block of 24 bytes
is definitely lost.
It seems the leak is limited to 24 bytes, but some critical pattern might
exploit a recursive behavior... :(
This could be an issue for some situations:
if the called functions are executed inside threads and the main program is the
transaction monitor itself, there is no way to assure the same thread called
xmlInitParser() is able to call xmlCleanupParser() too because the first thread
should remain locked until all the thread completed.
From a LIXA point of view, xmlInitParser() is called from the first thread
that calls tx_open() and xmlCleanupParser() is called from the last thread
that leaves tx_close(). The issue must be discussed with libxml2 development
team. Unfortunately, tx_open() can no be called from the main program and the
following functions from a different thread because this behavior would violate
XA standard: to avoid this issue a "proxy thread" should be used for XA
functions, but the "solution" is worst then the "problem".
If the multithreaded application has a main program - you are not writing a
library or a module - you can call
tx_open() in the main, before every thread is started
tx_close() in the main, after every thread is completed
this should avoid the memory leak. Pay attention the tx_open() at main level
is not inherited at the thread level: every thread must call its own tx_open()
too; this is only a workaround to force xmlInitParser() and xmlCleanupParser()
only at main program instead of at first starting thread / last ending thread.

After beta release, after interesting stuff like Python and PHP bindings, the 
custom containers developed for LIXA could be substituted with glib standard 
containers.
